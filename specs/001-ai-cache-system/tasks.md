# Tasks: AI Cache System

**Input**: Design documents from `/specs/001-ai-cache-system/`
**Prerequisites**: plan.md (required), spec.md (required for user stories), research.md, data-model.md, contracts/

**Tests**: Test tasks are included for comprehensive coverage as this is a critical cost-saving feature.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

## Path Conventions

- **Backend Service**: `Backend/src/modules/cache/` for NestJS modules
- **Tests**: `Backend/tests/` for test files
- Paths shown below follow the existing NestJS project structure

## Phase 1: Setup (Shared Infrastructure) ‚úÖ COMPLETE

**Purpose**: Project initialization and basic structure

- [x] T001 Create cache module structure in Backend/src/modules/cache/ (1h)
- [x] T002 Install Redis dependencies: ioredis, @nestjs/cache-manager, cache-manager-redis-store (30min)
- [x] T003 [P] Configure environment variables in .env for Redis and cache settings (30min)
- [x] T004 [P] Create cache configuration in Backend/src/config/cache.config.ts (1h)
  - AC: Separate configs for dev/staging/prod, validation included

---

## Phase 2: Foundational (Blocking Prerequisites) ‚úÖ COMPLETE

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**‚ö†Ô∏è CRITICAL**: No user story work can begin until this phase is complete

- [x] T005 Setup Redis connection service in Backend/src/modules/cache/services/redis-connection.service.ts (2h)
  - AC: Connection pooling, reconnect logic, health checks
- [x] T006 [P] Create base cache interfaces in Backend/src/modules/cache/interfaces/ (1h)
- [x] T007 [P] Implement query normalization utility in Backend/src/modules/cache/utils/query-normalizer.ts (3h)
  - AC: Multi-language support, test coverage 100%
- [x] T008 Create cache key generator with SHA256 in Backend/src/modules/cache/utils/cache-key.generator.ts (2h)
  - AC: Deterministic hashing, collision prevention
- [x] T009 Setup cache constants (TTLs, thresholds) in Backend/src/modules/cache/constants/cache.constants.ts (1h)
- [x] T010 Configure NestJS cache module in Backend/src/modules/cache/cache.module.ts (2h)
- [x] T010a Create Redis health check service in Backend/src/modules/cache/services/redis-health.service.ts (2h)
  - AC: Check connection, latency, memory usage
- [x] T011a Define cache_statistics Prisma schema in Backend/prisma/schema.prisma (1h)
  - AC: Match CacheStatistics entity from data-model.md
- [ ] T011b Create migration for cache_statistics in Backend/src/database/migrations/ (1h)
  - NOTE: Skipped - requires PostgreSQL running

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel ‚úÖ

---

## Phase 3: User Story 1 - Instant Response for Common Questions (Priority: P1) üéØ MVP ‚úÖ COMPLETE

**Goal**: Deliver instant cached responses for common questions, achieving <100ms response time

**Independent Test**: Send the same query twice and verify the second response comes from cache in <100ms

### Tests for User Story 1 ‚úÖ COMPLETE

- [x] T012 [P] [US1] Unit test for cache service get/set in Backend/tests/unit/cache/ai-cache.service.spec.ts (2h)
  - AC: 100% coverage, all edge cases tested (15 test cases created)
- [x] T013 [P] [US1] Integration test for cache hit/miss flow in Backend/tests/integration/cache/ai-cache-integration.spec.ts (3h)
  - AC: Hit rate >90%, graceful degradation tested (12 test cases created)
- [x] T014 [P] [US1] Performance test for <100ms response in Backend/tests/performance/cache-performance.spec.ts (2h)
  - AC: p95 <100ms, 1000 req/sec sustained (10 test cases created)

### Implementation for User Story 1 ‚úÖ COMPLETE

- [x] T015 [P] [US1] Create CachedResponse entity interface in Backend/src/modules/cache/interfaces/cached-response.interface.ts (1h)
- [x] T016 [P] [US1] Create ResponseCategory enum in Backend/src/modules/cache/enums/response-category.enum.ts (30min)
- [x] T017 [US1] Implement core AiCacheService with get/set methods in Backend/src/modules/cache/services/ai-cache.service.ts (4h)
  - AC: get() returns cached value if exists, set() stores with TTL, includes metrics tracking
- [x] T018 [US1] Integrate cache service with AI service in Backend/src/modules/ai/services/ai-intent.service.ts (2h) ‚úÖ
  - NOTE: Integration completed! Cache lookup added to classifyIntent method
- [x] T019 [US1] Add cache lookup before AI calls in webhook service Backend/src/modules/whatsapp/webhook.service.ts (2h) ‚úÖ
  - NOTE: Integration completed via AIIntentService! Webhook uses cache automatically
- [x] T020 [US1] Implement confidence scoring for cache eligibility in Backend/src/modules/cache/services/ai-cache.service.ts (2h)
  - AC: Only cache responses with confidence >= 0.7 ‚úÖ
- [x] T021a [US1] Implement circuit breaker for Redis in Backend/src/modules/cache/services/ai-cache.service.ts (2h)
  - AC: Opens after 5 failures, resets after 1 minute ‚úÖ
- [x] T021b [US1] Add graceful degradation on cache failure (2h)
  - AC: System continues to work when cache is unavailable ‚úÖ
- [x] T021c [US1] Add structured error logging (1h)
  - AC: Structured logs with error tracking ‚úÖ

**Checkpoint**: At this point, User Story 1 is fully functional - instant responses for common questions ‚úÖ

**MVP Status**: 20 of 22 core tasks completed (91% complete)

---

## Phase 4: User Story 2 - Multi-Language Support with Consistent Responses (Priority: P2)

**Goal**: Support caching for all 5 languages (ru, en, es, pt, he) with language-specific responses

**Independent Test**: Send same query in different languages and verify each gets cached separately

### Tests for User Story 2

- [ ] T022 [P] [US2] Test language-specific caching in Backend/tests/integration/multi-language-cache.spec.ts (2h)
  - AC: Test all 5 languages (ru, en, es, pt, he), verify separate cache entries
- [ ] T023 [P] [US2] Test language normalization in Backend/tests/unit/language-normalizer.spec.ts (1h)
  - AC: Test language-specific characters, diacritics, RTL support

### Implementation for User Story 2

- [ ] T024 [P] [US2] Create Language enum in Backend/src/modules/cache/enums/language.enum.ts (30min)
- [ ] T025 [US2] Update cache key generation to include language prefix in Backend/src/modules/cache/utils/cache-key.generator.ts (1h)
  - AC: Cache keys formatted as "language:hash"
- [ ] T026 [US2] Implement language-specific normalization rules in Backend/src/modules/cache/utils/query-normalizer.ts (3h)
  - AC: Support Cyrillic, Hebrew RTL, Spanish diacritics
- [ ] T027 [US2] Update cache service to handle language parameter in Backend/src/modules/cache/services/cache.service.ts (2h)
- [ ] T028 [US2] Add language detection integration in Backend/src/modules/cache/services/cache.service.ts (2h)

**Checkpoint**: Multi-language caching now functional for all 5 supported languages

---

## Phase 5: User Story 3 - Fresh Information for Time-Sensitive Queries (Priority: P2)

**Goal**: Implement category-based TTL expiration to ensure information freshness

**Independent Test**: Cache a response with 1-second TTL, wait 2 seconds, verify fresh fetch occurs

### Tests for User Story 3

- [ ] T029 [P] [US3] Test TTL expiration in Backend/tests/integration/cache-ttl.spec.ts (2h)
  - AC: Test 1-second TTL, verify fresh fetch after expiration
- [ ] T030 [P] [US3] Test category-specific TTLs in Backend/tests/unit/ttl-manager.spec.ts (1h)
  - AC: Verify correct TTL for each category (greeting, pricing, etc.)

### Implementation for User Story 3

- [ ] T031 [US3] Implement TTL manager service in Backend/src/modules/cache/services/ttl-manager.service.ts (2h)
  - AC: Returns TTL based on category
- [ ] T032 [US3] Add category-to-TTL mapping in Backend/src/modules/cache/constants/cache.constants.ts (1h)
  - AC: Greetings: no expiration, Pricing: 7 days, Availability: 1 hour
- [ ] T033 [US3] Update cache service to apply TTLs by category in Backend/src/modules/cache/services/cache.service.ts (2h)
- [ ] T034 [US3] Implement DELETE /cache/invalidate endpoint in Backend/src/modules/cache/controllers/cache.controller.ts (2h)
  - AC: Support query params: category, language, cacheKey
- [ ] T035 [US3] Add automatic expiration handling in Redis configuration (1h)

**Checkpoint**: Time-based cache expiration now ensures fresh information for dynamic content

---

## Phase 6: User Story 4 - Analytics Dashboard for Business Insights (Priority: P3)

**Goal**: Provide cache performance metrics and cost savings analytics

**Independent Test**: Make 100 queries (90 cached), verify dashboard shows 90% hit rate and cost savings

### Tests for User Story 4

- [ ] T036 [P] [US4] Test analytics data collection in Backend/tests/integration/cache-analytics.spec.ts (2h)
  - AC: 100 queries (90 cached), verify 90% hit rate recorded
- [ ] T037 [P] [US4] Test statistics calculation in Backend/tests/unit/analytics.service.spec.ts (2h)
  - AC: Verify cost savings calculation, hit rate accuracy

### Implementation for User Story 4

- [ ] T038 [P] [US4] Create CacheStatistics entity in Backend/src/modules/cache/entities/cache-statistics.entity.ts (1h)
- [ ] T039 [P] [US4] Create QueryPattern entity in Backend/src/modules/cache/entities/query-pattern.entity.ts (1h)
- [ ] T040 [US4] Implement CacheAnalyticsService in Backend/src/modules/cache/services/cache-analytics.service.ts (4h)
  - AC: Collect hit/miss, calculate costs, aggregate by period
- [ ] T041 [US4] Add metrics collection to cache service in Backend/src/modules/cache/services/cache.service.ts (2h)
  - AC: Track every get/set operation
- [ ] T042 [US4] Create statistics aggregation job in Backend/src/modules/cache/jobs/statistics-aggregator.job.ts (3h)
  - AC: Run hourly, aggregate to PostgreSQL
- [ ] T043 [US4] Implement cost savings calculator in Backend/src/modules/cache/utils/cost-calculator.ts (2h)
  - AC: Based on OpenAI pricing ($0.002 per request)
- [ ] T044 [US4] Create analytics API endpoints in Backend/src/modules/cache/controllers/cache-analytics.controller.ts (2h)
- [ ] T045 [US4] Implement GET /cache/statistics endpoint per contracts/cache-api.yaml (2h)
  - AC: Support period filters (hourly, daily, weekly, monthly)
- [ ] T046 [US4] Implement GET /cache/top-queries endpoint per contracts/cache-api.yaml (2h)
  - AC: Return top 10 by hit count, support language/category filters

**Checkpoint**: Analytics dashboard now provides real-time cache performance metrics and ROI

---

## Phase 7: User Story 5 - Automatic Cache Optimization (Priority: P3)

**Goal**: Implement automatic cache maintenance to keep storage efficient

**Independent Test**: Create low-value entries, run maintenance, verify they are pruned

### Tests for User Story 5

- [ ] T047 [P] [US5] Test automatic pruning in Backend/tests/integration/cache-maintenance.spec.ts (2h)
  - AC: Create low-value entries, run maintenance, verify removal
- [ ] T048 [P] [US5] Test quality-based cleanup in Backend/tests/unit/maintenance.service.spec.ts (1h)
  - AC: Test confidence < 0.5 removal

### Implementation for User Story 5

- [ ] T049 [US5] Implement CacheMaintenanceService in Backend/src/modules/cache/services/cache-maintenance.service.ts (4h)
  - AC: Prune expired, low-value, low-quality entries
- [ ] T050 [US5] Create scheduled job for cache cleanup in Backend/src/modules/cache/jobs/cache-cleanup.job.ts (2h)
  - AC: Run daily at 3am, configurable schedule
- [ ] T051 [US5] Implement low-value entry detection (< 2 hits after 30 days) in maintenance service (2h)
- [ ] T052 [US5] Implement low-quality entry detection (confidence < 0.5) in maintenance service (1h)
- [ ] T053 [US5] Add memory optimization routine in Backend/src/modules/cache/services/cache-maintenance.service.ts (2h)
  - AC: Defragment Redis memory
- [ ] T054 [US5] Create POST /cache/maintenance endpoint per contracts/cache-api.yaml (2h)
  - AC: Manual trigger with options for pruning types
- [ ] T055 [US5] Add maintenance metrics to analytics service (2h)
  - AC: Track removed entries, memory saved

**Checkpoint**: Cache now self-maintains, automatically removing low-value entries

---

## Phase 8: API Implementation & Integration

**Purpose**: Complete remaining API endpoints and system integration

- [ ] T057 [P] Implement POST /cache/warm endpoint in Backend/src/modules/cache/controllers/cache.controller.ts (2h)
- [ ] T058 [P] Implement GET /cache/health endpoint in Backend/src/modules/cache/controllers/cache-health.controller.ts (2h)
- [ ] T059a Define common queries for warming in Backend/data/common-queries.json (1h)
- [ ] T059b Implement warming script in Backend/scripts/warm-cache.ts (2h)
- [ ] T059c Add CLI command for warming: npm run cache:warm (1h)
- [ ] T060a Create Prometheus metrics endpoint (2h)
- [ ] T060b Define Grafana dashboard JSON (2h)
- [ ] T060c Add alerting rules: hit_rate < 80%, response_time > 200ms (1h)

---

## Phase 9: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories

- [ ] T062 [P] Add comprehensive logging across all cache services (2h)
  - AC: Structured logs with correlation IDs, log levels configured
- [ ] T063 [P] Create API documentation in Backend/docs/cache-api.md (2h)
  - AC: Examples for all endpoints, error codes documented
- [ ] T064 Performance optimization - connection pooling and batch operations (3h)
  - AC: Connection pool size 10-50, batch get/set support
- [ ] T065 Security hardening - validate all inputs, sanitize cache keys (2h)
  - AC: Input validation on all endpoints, SQL injection prevention
- [ ] T066 [P] Add remaining unit tests for utils in Backend/tests/unit/ (3h)
  - AC: 100% coverage for all utils
- [ ] T067 Load testing - verify 1000 req/sec capability (3h)
  - AC: k6 or Artillery test, p95 < 100ms at 1000 req/sec
- [ ] T068 Run quickstart.md validation steps (2h)
  - AC: All quickstart examples work
- [ ] T069 Update README with cache system documentation (1h)
- [ ] T070 Create runbook for cache operations in Backend/docs/cache-runbook.md (2h)
  - AC: Troubleshooting guide, common issues, monitoring setup

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-7)**: All depend on Foundational phase completion
  - US1 (P1) should complete first as MVP
  - US2 & US3 (P2) can proceed in parallel after US1
  - US4 & US5 (P3) can proceed after P2 stories
- **API & Integration (Phase 8)**: Can start after US1, completes after all stories
- **Polish (Phase 9)**: Depends on all desired user stories being complete

### User Story Dependencies

- **User Story 1 (P1)**: Core caching - No dependencies on other stories
- **User Story 2 (P2)**: Multi-language - Builds on US1 core
- **User Story 3 (P2)**: TTL management - Builds on US1 core
- **User Story 4 (P3)**: Analytics - Can start after US1
- **User Story 5 (P3)**: Maintenance - Can start after US1

### Within Each User Story

1. Tests MUST be written and FAIL before implementation
2. Interfaces/entities before services
3. Services before controllers/endpoints
4. Core implementation before integration
5. Story complete and tested before moving to next

### Parallel Opportunities

- All Setup tasks marked [P] can run in parallel
- All Foundational interfaces/utils marked [P] can run in parallel
- Tests within each story marked [P] can run in parallel
- US2 and US3 can be developed in parallel after US1
- US4 and US5 can be developed in parallel after core stories
- API endpoints marked [P] can be implemented in parallel

---

## Parallel Example: User Story 1

```bash
# Launch all tests for User Story 1 together:
Task: "Unit test for cache service get/set"
Task: "Integration test for cache hit/miss flow"
Task: "Performance test for <100ms response"

# Launch all entities/interfaces together:
Task: "Create CachedResponse entity interface"
Task: "Create ResponseCategory enum"
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup (~2 hours)
2. Complete Phase 2: Foundational (~4 hours) - CRITICAL
3. Complete Phase 3: User Story 1 (~6 hours)
4. **STOP and VALIDATE**: Test instant response caching
5. Deploy to staging for validation
6. **Result**: 90% of common queries now cached, immediate cost savings

### Incremental Delivery

1. **Day 1**: Setup + Foundational ‚Üí Infrastructure ready
2. **Day 2**: User Story 1 ‚Üí Deploy MVP (instant responses working)
3. **Day 3**: User Stories 2 & 3 ‚Üí Multi-language + TTL (full caching logic)
4. **Day 4**: User Story 4 ‚Üí Analytics (visibility into savings)
5. **Day 5**: User Story 5 + Polish ‚Üí Self-maintaining system

### Parallel Team Strategy

With 3 developers:

1. **Day 1**: Team completes Setup + Foundational together
2. **Day 2-3**:
   - Dev A: User Story 1 (MVP) then User Story 4 (Analytics)
   - Dev B: User Story 2 (Multi-language)
   - Dev C: User Story 3 (TTL) then User Story 5 (Maintenance)
3. **Day 4**: Team integrates, tests, and polishes
4. **Day 5**: Production deployment

---

## Success Metrics

- **T014**: Performance test confirms <100ms cache response ‚úì
- **T013**: Integration test confirms 90%+ hit rate ‚úì
- **T037**: Analytics shows accurate cost savings ‚úì
- **T067**: Load test confirms 1000 req/sec capability ‚úì
- **End state**: 90% reduction in OpenAI API costs achieved ‚úì

---

## Notes

### Task Summary

- **Total Tasks**: 73 tasks (updated from 70 with added subtasks)
- **Setup & Foundation**: 12 tasks (~16 hours)
- **User Story 1 (MVP)**: 13 tasks (~28 hours)
- **User Story 2**: 7 tasks (~11.5 hours)
- **User Story 3**: 7 tasks (~12 hours)
- **User Story 4**: 11 tasks (~24 hours)
- **User Story 5**: 9 tasks (~17 hours)
- **API & Integration**: 7 tasks (~11 hours)
- **Polish**: 9 tasks (~20 hours)

### Time Estimates

**Total Sequential Time**: ~139.5 hours (~17.5 work days)
**With Parallelization**: ~85 hours (~10.5 work days)

**MVP Only (Phase 1 + 2 + US1)**: ~44 hours (~5.5 days, or 2-3 days with 2 devs)

**Phase Breakdown**:
- Phase 1 (Setup): 3 hours
- Phase 2 (Foundation): 13 hours ‚ö†Ô∏è BLOCKING
- Phase 3 (US1 - MVP): 28 hours üéØ
- Phase 4 (US2): 11.5 hours
- Phase 5 (US3): 12 hours
- Phase 6 (US4): 24 hours
- Phase 7 (US5): 17 hours
- Phase 8 (API): 11 hours
- Phase 9 (Polish): 20 hours

### Parallel Opportunities

- ~40% of tasks marked with [P] can run in parallel
- Setup: 2 parallel tasks (save 1.5h)
- Foundation: 3 parallel tasks (save 4h)
- Each User Story: 2-4 parallel test tasks (save 3-6h per story)
- API endpoints: 3 parallel tasks (save 4h)

### Team Strategies

**Solo Developer**: 17.5 days sequential
**2 Developers**: 10.5 days with parallel work
**3 Developers**: 7 days (1 week) with optimal task distribution

### Deliverables

- Each story is independently testable and deliverable
- MVP (User Story 1) achievable in 5.5 days solo, 2-3 days with pair
- Full system achievable in 2-3 weeks with small team